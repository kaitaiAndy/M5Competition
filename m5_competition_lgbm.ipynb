{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M5 Forecasting\n",
    "\n",
    "[Introduction](#Introduction)\n",
    "\n",
    "\n",
    "[EDA](#EDA)\n",
    "\n",
    "To-do\n",
    "- Denoising\n",
    "\n",
    "Statistical Model\n",
    "- ARIMA\n",
    "- Exponential Smoothing\n",
    "- Theta Method\n",
    "\n",
    "Machine Learning Model\n",
    "- GBM\n",
    "- LSTM\n",
    "Multi-step ahead forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Goal\n",
    "Predict Sales data provided by Walmart **28** days into the future\n",
    "\n",
    "## Data\n",
    "sales_train.csv: this is our main training data. It has 1 column for each of the 1941 days from 2011-01-29 and 2016-05-22; not including the validation period of 28 days until 2016-06-19. It also includes the IDs for item, department, category, store, and state. The number of rows is 30490 for all combinations of 30490 items and 10 stores.\n",
    "\n",
    "sell_prices.csv: the store and item IDs together with the sales price of the item as a weekly average.\n",
    "\n",
    "calendar.csv: dates together with related features like day-of-the week, month, year, and an 3 binary flags for whether the stores in each state allowed purchases with SNAP food stamps at this date (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "util function\n",
    "https://www.kaggle.com/ratan123/m5-forecasting-lightgbm-with-timeseries-splits\n",
    "'''\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_name, sales_path='sales_train_validation.csv',\n",
    "             calendar_path='calendar.csv', price_path='sell_prices.csv'):\n",
    "    sales = pd.read_csv(os.path.join(dir_name, sales_path))\n",
    "    calendar = pd.read_csv(os.path.join(dir_name, calendar_path))\n",
    "    price = pd.read_csv(os.path.join(dir_name, price_path))\n",
    "    return sales, calendar, price\n",
    "#     return reduce_mem_usage(sales), reduce_mem_usage(calendar), reduce_mem_usage(price)\n",
    "\n",
    "sales, calendar, price = load_data('../m5-forecasting-accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>11619</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>2016-06-06</td>\n",
       "      <td>11619</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>11619</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1957</td>\n",
       "      <td>Ramadan starts</td>\n",
       "      <td>Religious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>11619</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>11619</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1959 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  wm_yr_wk    weekday  wday  month  year       d  \\\n",
       "0     2011-01-29     11101   Saturday     1      1  2011     d_1   \n",
       "1     2011-01-30     11101     Sunday     2      1  2011     d_2   \n",
       "2     2011-01-31     11101     Monday     3      1  2011     d_3   \n",
       "3     2011-02-01     11101    Tuesday     4      2  2011     d_4   \n",
       "4     2011-02-02     11101  Wednesday     5      2  2011     d_5   \n",
       "...          ...       ...        ...   ...    ...   ...     ...   \n",
       "1954  2016-06-05     11619     Sunday     2      6  2016  d_1955   \n",
       "1955  2016-06-06     11619     Monday     3      6  2016  d_1956   \n",
       "1956  2016-06-07     11619    Tuesday     4      6  2016  d_1957   \n",
       "1957  2016-06-08     11619  Wednesday     5      6  2016  d_1958   \n",
       "1958  2016-06-09     11619   Thursday     6      6  2016  d_1959   \n",
       "\n",
       "        event_name_1 event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  \\\n",
       "0                NaN          NaN          NaN          NaN        0        0   \n",
       "1                NaN          NaN          NaN          NaN        0        0   \n",
       "2                NaN          NaN          NaN          NaN        0        0   \n",
       "3                NaN          NaN          NaN          NaN        1        1   \n",
       "4                NaN          NaN          NaN          NaN        1        0   \n",
       "...              ...          ...          ...          ...      ...      ...   \n",
       "1954             NaN          NaN          NaN          NaN        1        1   \n",
       "1955             NaN          NaN          NaN          NaN        1        1   \n",
       "1956  Ramadan starts    Religious          NaN          NaN        1        1   \n",
       "1957             NaN          NaN          NaN          NaN        1        0   \n",
       "1958             NaN          NaN          NaN          NaN        1        1   \n",
       "\n",
       "      snap_WI  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "1954        1  \n",
       "1955        1  \n",
       "1956        0  \n",
       "1957        1  \n",
       "1958        1  \n",
       "\n",
       "[1959 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NicoleQi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (15,16,17,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Merge the dataframes\n",
    "'''\n",
    "# sales_train = pd.melt(sales, id_vars = ['id', 'item_id', 'dept_id',\n",
    "#                                         'cat_id', 'store_id', 'state_id'],\n",
    "#                       var_name = 'day',value_name = 'demand')\n",
    "# train_df = pd.merge(sales_train, calendar, how='left',\n",
    "#                     left_on=['day'], right_on=['d'])\n",
    "# train_df = reduce_mem_usage(train_df)\n",
    "# train_df = pd.merge(train_df, price, how='left', \n",
    "#                     on=['store_id','item_id','wm_yr_wk'])\n",
    "# train_df.to_csv('merged_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 6953.16 Mb (32.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMean + WK/M lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday: overlap with wday\n",
    "# wm_yr_wk: index for merging, no additional info\n",
    "# date: no additional info\n",
    "# d: overlap with day\n",
    "drop_col = ['wm_yr_wk', 'date', 'd', 'weekday']\n",
    "train_df.drop(drop_col, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58327370, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# week and month shift\n",
    "lags = list(range(1,8))+[28]\n",
    "for l in lags:\n",
    "    train_df[f\"lag_{l}\"] = train_df[['id', 'demand']].groupby('id')['demand'].shift(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean\n",
    "window = [7,28]\n",
    "for w in window:\n",
    "    for l in window:\n",
    "        train_df[f\"rmean_{l}_{w}\"] = train_df[['id',f\"lag_{l}\"]].groupby('id')[f\"lag_{l}\"].transform(\n",
    "                                                lambda x: x.rolling(w).mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../m5-forecasting-accuracy/merged_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NicoleQi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (12,13,14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading dataframe\n",
      "starting reducing mem use\n",
      "Mem. usage decreased to 7286.92 Mb (48.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../m5-forecasting-accuracy/merged_train.csv')\n",
    "print('finish loading dataframe')\n",
    "print('starting reducing mem use')\n",
    "train_df = reduce_mem_usage(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "item_id                0\n",
       "dept_id                0\n",
       "cat_id                 0\n",
       "store_id               0\n",
       "state_id               0\n",
       "day                    0\n",
       "demand                 0\n",
       "weekday                0\n",
       "wday                   0\n",
       "month                  0\n",
       "year                   0\n",
       "event_name_1    53631910\n",
       "event_type_1    53631910\n",
       "event_name_2    58205410\n",
       "event_type_2    58205410\n",
       "snap_CA                0\n",
       "snap_TX                0\n",
       "snap_WI                0\n",
       "sell_price      12299413\n",
       "lag_1              30499\n",
       "lag_2              60989\n",
       "lag_3              91479\n",
       "lag_4             121969\n",
       "lag_5             152459\n",
       "lag_6             182949\n",
       "lag_7             213439\n",
       "lag_28            853729\n",
       "rmean_7_7         396379\n",
       "rmean_28_7       1036669\n",
       "rmean_7_28       1036669\n",
       "rmean_28_28      1676959\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_na = pd.isna(train_df)\n",
    "check_na.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting event_name_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NicoleQi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting event_name_2\n",
      "converting event_type_1\n",
      "converting event_type_2\n"
     ]
    }
   ],
   "source": [
    "# change nans to string type\n",
    "nan_feature = [\"event_name_1\", \"event_name_2\", \"event_type_1\", \n",
    "               \"event_type_2\"]\n",
    "for f in nan_feature:\n",
    "    print(f\"converting {f}\")\n",
    "    train_df[f][check_na[f]] = 'NaN'\n",
    "\n",
    "\n",
    "# convert category features to non-negative int\n",
    "cat_feature = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id',\n",
    "              \"event_name_1\", \"event_name_2\", \"event_type_1\", \n",
    "               \"event_type_2\"]\n",
    "\n",
    "d = defaultdict(LabelEncoder)\n",
    "fit = train_df[cat_feature].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "train_df = pd.concat([train_df[train_df.columns[~train_df.columns.isin(cat_feature)]],\n",
    "                    fit], axis=1)\n",
    "# # Inverse the encoded\n",
    "# fit.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "\n",
    "# # Using the dictionary to label future data\n",
    "# df.apply(lambda x: d[x.name].transform(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "day              object\n",
       "demand            int16\n",
       "weekday          object\n",
       "wday               int8\n",
       "month              int8\n",
       "year              int16\n",
       "snap_CA            int8\n",
       "snap_TX            int8\n",
       "snap_WI            int8\n",
       "sell_price      float16\n",
       "lag_1           float16\n",
       "lag_2           float16\n",
       "lag_3           float16\n",
       "lag_4           float16\n",
       "lag_5           float16\n",
       "lag_6           float16\n",
       "lag_7           float16\n",
       "lag_28          float16\n",
       "rmean_7_7       float16\n",
       "rmean_28_7      float16\n",
       "rmean_7_28      float16\n",
       "rmean_28_28     float16\n",
       "item_id           int64\n",
       "dept_id           int64\n",
       "store_id          int64\n",
       "cat_id            int64\n",
       "state_id          int64\n",
       "event_name_1      int64\n",
       "event_name_2      int64\n",
       "event_type_1      int64\n",
       "event_type_2      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../m5-forecasting-accuracy/preprocessed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train lgbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../m5-forecasting-accuracy/preprocessed_train.csv')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3838.15 Mb (73.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['id', 'day', 'weekday','demand']\n",
    "X_train = train_df[train_df.columns[~train_df.columns.isin(drop_col)]]\n",
    "y_train = train_df['demand']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "cat_feature = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id',\n",
    "              \"event_name_1\", \"event_name_2\", \"event_type_1\", \n",
    "               \"event_type_2\", 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, valid_inds)\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feature, free_raw_data=False)\n",
    "\n",
    "valid_data = lgb.Dataset(X_train.loc[valid_inds], label = y_train.loc[valid_inds],\n",
    "                        categorical_feature=cat_feature, free_raw_data=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df, X_train, y_train, valid_inds,train_inds ; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        \"metric\": [\"rmse\"],\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 1200,\n",
    "    'num_leaves': 128,\n",
    "    \"min_data_in_leaf\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NicoleQi/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/NicoleQi/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tvalid_0's rmse: 14.1661\n",
      "[40]\tvalid_0's rmse: 7.01214\n",
      "[60]\tvalid_0's rmse: 3.90283\n",
      "[80]\tvalid_0's rmse: 2.7241\n",
      "[100]\tvalid_0's rmse: 2.33107\n",
      "[120]\tvalid_0's rmse: 2.21216\n",
      "[140]\tvalid_0's rmse: 2.16688\n",
      "[160]\tvalid_0's rmse: 2.1472\n",
      "[180]\tvalid_0's rmse: 2.13627\n",
      "[200]\tvalid_0's rmse: 2.13128\n",
      "[220]\tvalid_0's rmse: 2.12347\n",
      "[240]\tvalid_0's rmse: 2.1183\n",
      "[260]\tvalid_0's rmse: 2.11245\n",
      "[280]\tvalid_0's rmse: 2.10618\n",
      "[300]\tvalid_0's rmse: 2.09991\n",
      "[320]\tvalid_0's rmse: 35.9053\n",
      "[340]\tvalid_0's rmse: 22.4725\n",
      "[360]\tvalid_0's rmse: 11.6977\n",
      "[380]\tvalid_0's rmse: 7.49529\n",
      "[400]\tvalid_0's rmse: 4.38698\n",
      "[420]\tvalid_0's rmse: 3.18768\n",
      "[440]\tvalid_0's rmse: 2.46608\n",
      "[460]\tvalid_0's rmse: 2.30347\n",
      "[480]\tvalid_0's rmse: 2.23412\n",
      "[500]\tvalid_0's rmse: 2.17668\n",
      "[520]\tvalid_0's rmse: 2.14594\n",
      "[540]\tvalid_0's rmse: 2.11752\n",
      "[560]\tvalid_0's rmse: 2.1072\n",
      "[580]\tvalid_0's rmse: 2.10141\n",
      "[600]\tvalid_0's rmse: 2.09706\n",
      "[620]\tvalid_0's rmse: 2.08967\n",
      "[640]\tvalid_0's rmse: 2.08255\n",
      "[660]\tvalid_0's rmse: 2.07656\n",
      "[680]\tvalid_0's rmse: 2.07245\n",
      "[700]\tvalid_0's rmse: 2.06818\n",
      "[720]\tvalid_0's rmse: 2.0661\n",
      "[740]\tvalid_0's rmse: 2.062\n",
      "[760]\tvalid_0's rmse: 2.06088\n",
      "[780]\tvalid_0's rmse: 2.05822\n",
      "[800]\tvalid_0's rmse: 2.05669\n",
      "[820]\tvalid_0's rmse: 2.05334\n",
      "[840]\tvalid_0's rmse: 2.05266\n",
      "[860]\tvalid_0's rmse: 2.05193\n",
      "[880]\tvalid_0's rmse: 2.04803\n"
     ]
    }
   ],
   "source": [
    "m_lgb = lgb.train(params, train_data, valid_sets = [valid_data], verbose_eval=20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
